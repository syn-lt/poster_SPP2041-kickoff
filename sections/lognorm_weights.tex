\columnbreak
\section*{\LARGE Log-normal distributions of synaptic weights in noise driven networks}

In cortical circuits the distribution of synaptic weights has been repeatedly reported to be log-normal \cite{Song2005}. A number of computational models address the how such a weight distribution might arise from network dynamics. Here we test a hypothesis that log-normal weight distributions emerge from network dynamics in which LTP dominates and in which synaptic scaling takes the role of keeping weights from growing too large.

\section*{Network model}

The network considered here consist of $N$ randomly connected ($p=0.1$) conductance based leaky integrate-and-fire neurons. The differential equation for a neuron's membrane voltage $V$ is
%
\begin{align}
 \tau_m\, \frac{dV}{dt}  = E_l - V + g_e \,(E_e - V) +  \xi_{\mathrm{ext}}(t).
\end{align}
%
When synaptic transmission is active ($\Theta_{\text{trans}}=1$), the conductance $g_e$ is increased by $w_i$ at times $t_i^k$ of spikes from connected neurons with index $i$,
%
\begin{align}
 \frac{d ge}{dt} = - \frac{g_e}{\tau_e} +  \Theta_{\text{trans}}\, \sum_i w_i \sum_{k} \delta(t-t_i^k)
\end{align}
%
Spike-timing dependent plasticity is implemented in the form of long-term potentiation (LTP). The weight $w$ changes for $\Delta t = t_{\text{post}}-t_{\text{pre}} > 0$ as
\begin{align}
 \Delta w =  A_{\text{LTP}} \exp\left(\frac{\Delta t}{\tau_{\text{LTP}}}\right).
\end{align}
%
Multiplicative synaptic scaling acts homeostatic mechanism and prevents weights from unbounded growth. The incoming weights $w_j$ to a given neuron are scaled as
%
\begin{align}
 w_j \to w_j \left(1+ \eta_{\text{SN}} \left( \frac{W_{\text{target}}}{\sum_k w_k} -1\right) \right),
\end{align}
%
where $\sum_k w_k$ sums over all incoming weights and $W_target$ is a set target for the sum.


\section*{Results}

In the first part we disabled synaptic transmission is explicitly not part of this model as we want test here the developement 


\vspace{1.2cm}
\begin{overpic}[width=.49\columnwidth]%
  % 110, 133
  {figures/syn_lnt_gnw_e07036_16.pdf}
  \put(11,60){\normalfont \textbf{A}}
\end{overpic}
\begin{overpic}[width=.49\columnwidth]%
  % 110, 133
  {figures/syn_lnt_gnw_e07036_17.pdf}
  \put(11,60){\normalfont \textbf{B}}
\end{overpic}
\captionof{figure}{\label{fig:loglorm_LTP}}
\vspace{3cm}




\vspace{1.2cm}
\begin{overpic}[width=.49\columnwidth]%
  % 110, 133
  {figures/syn_lnt_gnw_b20efe_0_highmem.pdf}
  \put(11,60){\normalfont \textbf{A}}
\end{overpic}
\begin{overpic}[width=.49\columnwidth]%
  % 110, 133
  {figures/syn_lnt_gnw_b20efe_0_lowmem.pdf}
  \put(11,60){\normalfont \textbf{B}}
\end{overpic}
\captionof{figure}{$T=\text{\SI{900}{s}}$, LTD=-0.1 LTP \label{fig:loglorm_rec}}
\vspace{3cm}



\section*{Coupled Networks}

